version: '3.8'

services:
  qdrant:
    image: qdrant/qdrant:latest # It is recommended to specify a specific version
    container_name: dcsm_qdrant
    ports:
      - "6333:6333" # gRPC порт Qdrant
      - "6334:6334" # HTTP REST порт Qdrant (для UI, если он есть)
    volumes:
      - ./qdrant_storage:/qdrant/storage # Персистентное хранилище данных Qdrant
    networks:
      - dcsm_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6334/healthz"] # Проверка через REST API
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s # Дать время Qdrant на запуск перед первой проверкой

  glm:
    build:
      context: ./dcs_memory/services/glm
      dockerfile: Dockerfile
    container_name: dcsm_glm
    ports:
      - "50051:50051" # gRPC порт GLM
    environment:
      # QDRANT_HOST уже установлен в "qdrant" в Dockerfile, но можно переопределить здесь
      # QDRANT_HOST: qdrant
      # QDRANT_PORT: 6333
      # GRPC_LISTEN_ADDRESS: "[::]:50051"
      # SQLITE_DB_FILENAME: glm_metadata.sqlite3 # Использует значение по умолчанию из Dockerfile
      DEFAULT_VECTOR_SIZE: "384" # Пример, если KPS использует all-MiniLM-L6-v2 (384)
                                 # Это должно соответствовать KPS.DEFAULT_VECTOR_SIZE
    depends_on:
      qdrant:
        condition: service_healthy # Ждать, пока Qdrant не станет healthy
    networks:
      - dcsm_network
    # volumes: # Если нужно монтировать код для разработки
    #   - ./dcs_memory/services/glm:/service

  kps:
    build:
      context: ./dcs_memory/services/kps
      dockerfile: Dockerfile
    container_name: dcsm_kps
    ports:
      - "50052:50052" # gRPC порт KPS
    environment:
      # GLM_SERVICE_ADDRESS уже "glm:50051" в Dockerfile
      # KPS_GRPC_LISTEN_ADDRESS: "[::]:50052"
      SENTENCE_TRANSFORMER_MODEL: "all-MiniLM-L6-v2" # Явно указываем модель
      DEFAULT_VECTOR_SIZE: "384" # Должно соответствовать GLM.DEFAULT_VECTOR_SIZE
      # Для скачивания моделей sentence-transformers может потребоваться доступ в интернет из контейнера
      # и место в /root/.cache/torch или /root/.cache/huggingface/transformers
      # Можно монтировать volume для кэша моделей, чтобы не скачивать каждый раз при пересборке (если не в образе)
      # HUGGING_FACE_HUB_CACHE: /root/.cache/huggingface # Пример
      # TORCH_HOME: /root/.cache/torch
    depends_on:
      glm:
        condition: service_started # Или healthcheck, если будет добавлен в GLM
    networks:
      - dcsm_network
    # volumes:
    #   - ./dcs_memory/services/kps:/service
      # - kps_model_cache:/root/.cache # Пример монтирования кэша моделей

  swm:
    build:
      context: ./dcs_memory/services/swm
      dockerfile: Dockerfile
    container_name: dcsm_swm
    ports:
      - "50053:50053" # gRPC порт SWM
    environment:
      # GLM_SERVICE_ADDRESS уже "glm:50051" в Dockerfile
      # SWM_GRPC_LISTEN_ADDRESS: "[::]:50053"
      SWM_INDEXED_METADATA_KEYS: "type,source" # Пример индексируемых ключей
      # SWM_CACHE_MAX_SIZE: 200
    depends_on:
      glm:
        condition: service_started # Или healthcheck, если будет добавлен в GLM
    networks:
      - dcsm_network
    # volumes:
    #   - ./dcs_memory/services/swm:/service

networks:
  dcsm_network:
    driver: bridge

# volumes: # Если используется volume для кэша моделей KPS
#   kps_model_cache:
#     driver: local
